{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nextbit Test\n",
    "\n",
    "### Data description\n",
    "`deaths.csv` contains US data, for 1997-2002, from police-reported car crashes in which there is a harmful event (people or property), and from which at least one vehicle was towed. Data are restricted to front-seat occupants, include only a subset of the variables recorded, and are restricted in other ways also.\n",
    "\n",
    "**Format:**\n",
    "A data frame with 26217 observations on the following 15 variables.\n",
    "\n",
    "- `dvcat`: ordered factor with levels (estimated impact speeds) 1-9km/h, 10-24, 25-39, 40-54, 55+\n",
    "- `weight`:\n",
    "observation weights, albeit of uncertain accuracy, designed to account for varying sampling probabilities.\n",
    "- `dead`:\n",
    "factor with levels alive dead\n",
    "- `airbag`:\n",
    "a factor with levels none airbag\n",
    "- `seatbelt`:\n",
    "a factor with levels none belted\n",
    "- `frontal`:\n",
    "a numeric vector; 0 = non-frontal, 1=frontal impact\n",
    "- `sex`:\n",
    "a factor with levels f m\n",
    "- `ageOFocc`:\n",
    "age of occupant in years\n",
    "- `yearacc`:\n",
    "year of accident\n",
    "- `yearVeh`:\n",
    "Year of model of vehicle; a numeric vector\n",
    "- `abcat`:\n",
    "did one or more (driver or passenger) airbag(s) deploy? This factor has levels deploy nodeploy unavail\n",
    "- `occRole`:\n",
    "a factor with levels driver pass\n",
    "- `deploy`:\n",
    "a numeric vector: 0 if an airbag was unavailable or did not deploy; 1 if one or more bags deployed.\n",
    "- `injSeverity`:\n",
    "a numeric vector; 0:none, 1:possible injury, 2:no incapacity, 3:incapacity, 4:killed; 5:unknown, 6:prior death\n",
    "- `caseid`:\n",
    "character, created by pasting together the populations sampling unit, the case number, and the vehicle number. Within each year, use this to uniquely identify the vehicle.\n",
    "\n",
    "### Exercises\n",
    "- **E1.** Develop different models to predict the variable `dead` (alive or dead). Explain your choices.\n",
    "- **E2.** Select the best model and explain your choice.\n",
    "- **E3.** *(optional)* Train a neural network to predict the variable `dead`. Explain your choices. Did you achieve a better performance with respect to the model selected in **E2.**? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import resample, shuffle\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dvcat</th>\n",
       "      <th>weight</th>\n",
       "      <th>dead</th>\n",
       "      <th>airbag</th>\n",
       "      <th>seatbelt</th>\n",
       "      <th>frontal</th>\n",
       "      <th>sex</th>\n",
       "      <th>ageOFocc</th>\n",
       "      <th>yearacc</th>\n",
       "      <th>yearVeh</th>\n",
       "      <th>abcat</th>\n",
       "      <th>occRole</th>\n",
       "      <th>deploy</th>\n",
       "      <th>injSeverity</th>\n",
       "      <th>caseid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25-39</td>\n",
       "      <td>25.069</td>\n",
       "      <td>alive</td>\n",
       "      <td>none</td>\n",
       "      <td>belted</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>26</td>\n",
       "      <td>1997</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>unavail</td>\n",
       "      <td>driver</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2:3:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10-24</td>\n",
       "      <td>25.069</td>\n",
       "      <td>alive</td>\n",
       "      <td>airbag</td>\n",
       "      <td>belted</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>72</td>\n",
       "      <td>1997</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>deploy</td>\n",
       "      <td>driver</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2:3:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10-24</td>\n",
       "      <td>32.379</td>\n",
       "      <td>alive</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>69</td>\n",
       "      <td>1997</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>unavail</td>\n",
       "      <td>driver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2:5:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25-39</td>\n",
       "      <td>495.444</td>\n",
       "      <td>alive</td>\n",
       "      <td>airbag</td>\n",
       "      <td>belted</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>53</td>\n",
       "      <td>1997</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>deploy</td>\n",
       "      <td>driver</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2:10:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25-39</td>\n",
       "      <td>25.069</td>\n",
       "      <td>alive</td>\n",
       "      <td>none</td>\n",
       "      <td>belted</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>32</td>\n",
       "      <td>1997</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>unavail</td>\n",
       "      <td>driver</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2:11:1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dvcat   weight   dead  airbag seatbelt  frontal sex  ageOFocc  yearacc  \\\n",
       "0  25-39   25.069  alive    none   belted        1   f        26     1997   \n",
       "1  10-24   25.069  alive  airbag   belted        1   f        72     1997   \n",
       "2  10-24   32.379  alive    none     none        1   f        69     1997   \n",
       "3  25-39  495.444  alive  airbag   belted        1   f        53     1997   \n",
       "4  25-39   25.069  alive    none   belted        1   f        32     1997   \n",
       "\n",
       "   yearVeh    abcat occRole  deploy  injSeverity  caseid  \n",
       "0   1990.0  unavail  driver       0          3.0   2:3:1  \n",
       "1   1995.0   deploy  driver       1          1.0   2:3:2  \n",
       "2   1988.0  unavail  driver       0          4.0   2:5:1  \n",
       "3   1995.0   deploy  driver       1          1.0  2:10:1  \n",
       "4   1988.0  unavail  driver       0          3.0  2:11:1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv(\"deaths.csv\") # read the csv\n",
    "X.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "X.head() # visualize data frame head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dvcat            0\n",
       "weight           0\n",
       "dead             0\n",
       "airbag           0\n",
       "seatbelt         0\n",
       "frontal          0\n",
       "sex              0\n",
       "ageOFocc         0\n",
       "yearacc          0\n",
       "yearVeh          1\n",
       "abcat            0\n",
       "occRole          0\n",
       "deploy           0\n",
       "injSeverity    153\n",
       "caseid           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum() # check for missing values\n",
    "\n",
    "# injSeverity and yearacc has missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alive    25037\n",
       "dead      1180\n",
       "Name: dead, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['dead'].value_counts() # the target class is imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing missing value\n",
    "I have chosen to impute the missing values for variable 'injSeverity' because there are a considerables no.of rows with missing value for Series 'injSeverity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# impute missing values with 5.0 or 'unknown' values since \n",
    "X.loc[X[\"injSeverity\"].isnull(), \"injSeverity\"] = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop row(s) containing missing values. One missing value\n",
    "# for the variable 'yearVeh' is dropped\n",
    "X.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding\n",
    "Label encoding is done because the RF classifier is unable to handle character values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# performing label encoding for columns with string values\n",
    "\n",
    "# dead column\n",
    "X['dead'] = X.dead.map({'alive': 1, 'dead': 0})\n",
    "\n",
    "# airbag column\n",
    "X['airbag'] = X.airbag.map({'airbag': 1, 'none': 0})\n",
    "\n",
    "# seatbelt column\n",
    "X['seatbelt'] = X.seatbelt.map({'belted': 1, 'none': 0})\n",
    "\n",
    "# sex column\n",
    "X['sex'] = X.sex.map({'m': 1, 'f': 0})\n",
    "\n",
    "# abcat column\n",
    "X['abcat'] = X.abcat.map({'unavail': 2, 'deploy': 1, 'nodeploy': 0})\n",
    "\n",
    "# occRole column\n",
    "X['occRole'] = X.occRole.map({'driver': 1, 'pass': 0})\n",
    "\n",
    "# dvcat column\n",
    "X['dvcat'] = X.dvcat.map({'1-9km/h': 0, '10-24': 1, '25-39': 2, '40-54': 3, '55+': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dvcat</th>\n",
       "      <th>weight</th>\n",
       "      <th>dead</th>\n",
       "      <th>airbag</th>\n",
       "      <th>seatbelt</th>\n",
       "      <th>frontal</th>\n",
       "      <th>sex</th>\n",
       "      <th>ageOFocc</th>\n",
       "      <th>yearacc</th>\n",
       "      <th>yearVeh</th>\n",
       "      <th>abcat</th>\n",
       "      <th>occRole</th>\n",
       "      <th>deploy</th>\n",
       "      <th>injSeverity</th>\n",
       "      <th>caseid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>25.069</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1997</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2:3:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25.069</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>1997</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2:3:2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32.379</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>1997</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2:5:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>495.444</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>1997</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2:10:1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>25.069</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1997</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2:11:1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dvcat   weight  dead  airbag  seatbelt  frontal  sex  ageOFocc  yearacc  \\\n",
       "0      2   25.069     1       0         1        1    0        26     1997   \n",
       "1      1   25.069     1       1         1        1    0        72     1997   \n",
       "2      1   32.379     1       0         0        1    0        69     1997   \n",
       "3      2  495.444     1       1         1        1    0        53     1997   \n",
       "4      2   25.069     1       0         1        1    0        32     1997   \n",
       "\n",
       "   yearVeh  abcat  occRole  deploy  injSeverity  caseid  \n",
       "0   1990.0      2        1       0          3.0   2:3:1  \n",
       "1   1995.0      1        1       1          1.0   2:3:2  \n",
       "2   1988.0      2        1       0          4.0   2:5:1  \n",
       "3   1995.0      1        1       1          1.0  2:10:1  \n",
       "4   1988.0      2        1       0          3.0  2:11:1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head() # visualize data after encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = X.pop('dead') # target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# divide the dataset into train and test set.\n",
    "# train set will be used to build the model\n",
    "# test set will be used to evaluate the model\n",
    "\n",
    "# stratified split is used to preserve the ratio between the majority\n",
    "# and minority class\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=2)\n",
    "for train_index, test_index in ss.split(X, Y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X.loc[train_index,], X.loc[test_index,]\n",
    "    y_train, y_test = Y.loc[train_index,], Y.loc[test_index,]\n",
    "    \n",
    "\n",
    "X_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# drop the unique identifier 'caseid'\n",
    "X_train.drop(['caseid'], axis=1, inplace=True)\n",
    "\n",
    "X_train.dropna(how='any', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dvcat</th>\n",
       "      <th>weight</th>\n",
       "      <th>airbag</th>\n",
       "      <th>seatbelt</th>\n",
       "      <th>frontal</th>\n",
       "      <th>sex</th>\n",
       "      <th>ageOFocc</th>\n",
       "      <th>yearacc</th>\n",
       "      <th>yearVeh</th>\n",
       "      <th>abcat</th>\n",
       "      <th>occRole</th>\n",
       "      <th>deploy</th>\n",
       "      <th>injSeverity</th>\n",
       "      <th>dead</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>1.0</td>\n",
       "      <td>763.016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15861</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.579</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13220</th>\n",
       "      <td>1.0</td>\n",
       "      <td>725.853</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23334</th>\n",
       "      <td>4.0</td>\n",
       "      <td>649.395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dvcat   weight  airbag  seatbelt  frontal  sex  ageOFocc  yearacc  \\\n",
       "1772     1.0  763.016     1.0       1.0      0.0  0.0      31.0   1997.0   \n",
       "15861    1.0   10.579     0.0       1.0      1.0  1.0      27.0   2000.0   \n",
       "13220    1.0  725.853     1.0       1.0      0.0  0.0      30.0   2000.0   \n",
       "2349     0.0   97.905     1.0       1.0      0.0  0.0      28.0   1997.0   \n",
       "23334    4.0  649.395     1.0       1.0      1.0  1.0      22.0   2002.0   \n",
       "\n",
       "       yearVeh  abcat  occRole  deploy  injSeverity  dead  \n",
       "1772    1992.0    0.0      1.0     0.0          0.0   1.0  \n",
       "15861   1991.0    2.0      0.0     0.0          1.0   1.0  \n",
       "13220   1996.0    0.0      0.0     0.0          1.0   1.0  \n",
       "2349    1996.0    0.0      0.0     0.0          0.0   1.0  \n",
       "23334   2001.0    1.0      1.0     1.0          1.0   1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE: Synthetic Minority Oversampling TEchnique\n",
    "\n",
    "Since the dataset is highly imbalanced, Neural Net might not work with such high imbalance. Thus, oversampling of the minority class is needed. This is done through the DMwR package in R. Hence, I am exporting the dataset to be used in R.\n",
    "\n",
    "Python implementation of SMOTE also exists but I faced some problems while using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export the data frames to csv\n",
    "train_path = \"/home/subhankar/Documents/sklearn/nextbit-test/train_data_new.csv\"\n",
    "X_train.to_csv(path_or_buf=train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R code:\n",
    "\n",
    "library(DMwR)\n",
    "dataset <- read.csv(\"train_data_new.csv\") <br/>\n",
    "dataset\\$dead <- as.factor(dataset\\$dead) <br/>\n",
    "newdata <- SMOTE(dataset\\$dead~., dataset, perc.over = 2000, perc.under = 100) <br/>\n",
    "write.csv(newdata, 'smoted_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"smoted_train_data.csv\")\n",
    "X_train = shuffle(X_train)\n",
    "y_train = X_train.pop('dead')\n",
    "X_train.drop(labels=['Unnamed: 0', 'X'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    17220\n",
       "1    16400\n",
       "Name: dead, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() # now the SMOTE-ed dataset has almost equal representations for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one hot encoding\n",
    "y_one_hot_train = np.eye(2)[y_train]\n",
    "\n",
    "# convert the dataframe into a numpy array\n",
    "X_train = X_train.as_matrix()\n",
    "\n",
    "test_id = X_test.pop('caseid') # drop unwanted column\n",
    "# perform one hot encoding\n",
    "y_one_hot_test = np.eye(2)[y_test]\n",
    "\n",
    "# convert the dataframe into a numpy array\n",
    "X_test = X_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare weights and biases\n",
    "w1_initial = np.random.normal(size=(13, 5)).astype(np.float32)\n",
    "w2_initial = np.random.normal(size=(5, 2)).astype(np.float32)\n",
    "\n",
    "b1_initial = np.random.normal(size=(5)).astype(np.float32)\n",
    "b2_initial = np.random.normal(size=(2)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _create_network():\n",
    "    \n",
    "    # layer 1\n",
    "    with tf.variable_scope('fc_1'):\n",
    "        w1 = tf.Variable(w1_initial)\n",
    "        b1 = tf.Variable(b1_initial)\n",
    "        fc1 = tf.add(tf.matmul(x, w1), b1)\n",
    "        fc1 = tf.nn.sigmoid(fc1)\n",
    "    \n",
    "    # layer 2\n",
    "    with tf.variable_scope('fc_2'):\n",
    "        w2 = tf.Variable(w2_initial)\n",
    "        b2 = tf.Variable(b2_initial)\n",
    "        fc2 = tf.add(tf.matmul(fc1, w2), b2)\n",
    "        #fc2 = tf.nn.sigmoid(fc2)\n",
    "    pred = fc2\n",
    "    \n",
    "    # calculate cost\n",
    "    \n",
    "    #weights = tf.reduce_sum(class_weights * y, axis=1)\n",
    "    #unweighted_losses = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=pred)\n",
    "    #weighted_losses = unweighted_losses * weights\n",
    "    #cost = tf.reduce_mean(weighted_losses)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    #cost = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=pred, targets=y, pos_weight=0.04))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost, global_step=global_step)\n",
    "    \n",
    "    # evaluate model\n",
    "    y_prediction = tf.argmax(pred, 1)\n",
    "    correct_pred = tf.equal(y_prediction, tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    return cost, optimizer, accuracy, y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Iteration: 1000. Mini-batch cost: 0.6948. Train accuracy:0.4800\n",
      "Epoch: 2. Iteration: 2000. Mini-batch cost: 0.6427. Train accuracy:0.5600\n",
      "Epoch: 4. Iteration: 3000. Mini-batch cost: 0.5448. Train accuracy:0.7000\n",
      "Epoch: 5. Iteration: 4000. Mini-batch cost: 0.6279. Train accuracy:0.6800\n",
      "Epoch: 7. Iteration: 5000. Mini-batch cost: 0.6204. Train accuracy:0.6400\n",
      "Epoch: 8. Iteration: 6000. Mini-batch cost: 0.6744. Train accuracy:0.6000\n",
      "Epoch: 10. Iteration: 7000. Mini-batch cost: 0.6987. Train accuracy:0.5200\n",
      "Epoch: 11. Iteration: 8000. Mini-batch cost: 0.4325. Train accuracy:0.8600\n",
      "Epoch: 13. Iteration: 9000. Mini-batch cost: 0.5666. Train accuracy:0.7400\n",
      "Epoch: 14. Iteration: 10000. Mini-batch cost: 0.5314. Train accuracy:0.7400\n",
      "Epoch: 16. Iteration: 11000. Mini-batch cost: 0.7320. Train accuracy:0.5800\n",
      "Epoch: 17. Iteration: 12000. Mini-batch cost: 0.4997. Train accuracy:0.7800\n",
      "Epoch: 19. Iteration: 13000. Mini-batch cost: 0.6046. Train accuracy:0.6800\n",
      "Epoch: 20. Iteration: 14000. Mini-batch cost: 0.6337. Train accuracy:0.6200\n",
      "Epoch: 22. Iteration: 15000. Mini-batch cost: 0.5553. Train accuracy:0.7400\n",
      "Epoch: 23. Iteration: 16000. Mini-batch cost: 0.7321. Train accuracy:0.6000\n",
      "Epoch: 25. Iteration: 17000. Mini-batch cost: 0.5168. Train accuracy:0.8000\n",
      "Epoch: 26. Iteration: 18000. Mini-batch cost: 0.6075. Train accuracy:0.6600\n",
      "Epoch: 28. Iteration: 19000. Mini-batch cost: 0.5601. Train accuracy:0.7400\n",
      "Epoch: 29. Iteration: 20000. Mini-batch cost: 0.4328. Train accuracy:0.8400\n",
      "Epoch: 31. Iteration: 21000. Mini-batch cost: 0.7219. Train accuracy:0.5800\n",
      "Epoch: 32. Iteration: 22000. Mini-batch cost: 0.1664. Train accuracy:0.9600\n",
      "Epoch: 34. Iteration: 23000. Mini-batch cost: 0.1796. Train accuracy:0.9400\n",
      "Epoch: 35. Iteration: 24000. Mini-batch cost: 0.2950. Train accuracy:0.9000\n",
      "Epoch: 37. Iteration: 25000. Mini-batch cost: 0.1074. Train accuracy:0.9800\n",
      "Epoch: 38. Iteration: 26000. Mini-batch cost: 0.2153. Train accuracy:0.9400\n",
      "Epoch: 40. Iteration: 27000. Mini-batch cost: 0.0742. Train accuracy:0.9800\n",
      "Epoch: 41. Iteration: 28000. Mini-batch cost: 0.1166. Train accuracy:0.9800\n",
      "Epoch: 43. Iteration: 29000. Mini-batch cost: 0.1532. Train accuracy:0.9400\n",
      "Epoch: 44. Iteration: 30000. Mini-batch cost: 0.0463. Train accuracy:0.9800\n",
      "Epoch: 46. Iteration: 31000. Mini-batch cost: 0.1514. Train accuracy:0.9600\n",
      "Epoch: 47. Iteration: 32000. Mini-batch cost: 0.0202. Train accuracy:1.0000\n",
      "Epoch: 49. Iteration: 33000. Mini-batch cost: 0.0893. Train accuracy:0.9600\n",
      "Epoch: 50. Iteration: 34000. Mini-batch cost: 0.0354. Train accuracy:0.9800\n",
      "Epoch: 52. Iteration: 35000. Mini-batch cost: 0.0702. Train accuracy:0.9800\n",
      "Epoch: 53. Iteration: 36000. Mini-batch cost: 0.2211. Train accuracy:0.9400\n",
      "Epoch: 54. Iteration: 37000. Mini-batch cost: 0.2248. Train accuracy:0.9400\n",
      "Epoch: 56. Iteration: 38000. Mini-batch cost: 0.1561. Train accuracy:0.9600\n",
      "Epoch: 57. Iteration: 39000. Mini-batch cost: 0.0747. Train accuracy:0.9800\n",
      "Epoch: 59. Iteration: 40000. Mini-batch cost: 0.1022. Train accuracy:0.9800\n",
      "Epoch: 60. Iteration: 41000. Mini-batch cost: 0.0416. Train accuracy:0.9800\n",
      "Epoch: 62. Iteration: 42000. Mini-batch cost: 0.2595. Train accuracy:0.9200\n",
      "Epoch: 63. Iteration: 43000. Mini-batch cost: 0.0622. Train accuracy:0.9800\n",
      "Epoch: 65. Iteration: 44000. Mini-batch cost: 0.2092. Train accuracy:0.9400\n",
      "Epoch: 66. Iteration: 45000. Mini-batch cost: 0.0600. Train accuracy:0.9800\n",
      "Epoch: 68. Iteration: 46000. Mini-batch cost: 0.1290. Train accuracy:0.9200\n",
      "Epoch: 69. Iteration: 47000. Mini-batch cost: 0.1436. Train accuracy:0.9600\n",
      "Epoch: 71. Iteration: 48000. Mini-batch cost: 0.0262. Train accuracy:1.0000\n",
      "Epoch: 72. Iteration: 49000. Mini-batch cost: 0.0770. Train accuracy:0.9800\n",
      "Epoch: 74. Iteration: 50000. Mini-batch cost: 0.1017. Train accuracy:0.9400\n",
      "Epoch: 75. Iteration: 51000. Mini-batch cost: 0.1014. Train accuracy:0.9600\n",
      "Epoch: 77. Iteration: 52000. Mini-batch cost: 0.1669. Train accuracy:0.9200\n",
      "Epoch: 78. Iteration: 53000. Mini-batch cost: 0.0255. Train accuracy:1.0000\n",
      "Epoch: 80. Iteration: 54000. Mini-batch cost: 0.1057. Train accuracy:0.9800\n",
      "Epoch: 81. Iteration: 55000. Mini-batch cost: 0.1237. Train accuracy:0.9800\n",
      "Epoch: 83. Iteration: 56000. Mini-batch cost: 0.2177. Train accuracy:0.9400\n",
      "Epoch: 84. Iteration: 57000. Mini-batch cost: 0.0562. Train accuracy:0.9800\n",
      "Epoch: 86. Iteration: 58000. Mini-batch cost: 0.0549. Train accuracy:1.0000\n",
      "Epoch: 87. Iteration: 59000. Mini-batch cost: 0.1159. Train accuracy:0.9400\n",
      "Epoch: 89. Iteration: 60000. Mini-batch cost: 0.1421. Train accuracy:0.9400\n",
      "Epoch: 90. Iteration: 61000. Mini-batch cost: 0.1313. Train accuracy:0.9600\n",
      "Epoch: 92. Iteration: 62000. Mini-batch cost: 0.1700. Train accuracy:0.9600\n",
      "Epoch: 93. Iteration: 63000. Mini-batch cost: 0.1114. Train accuracy:0.9800\n",
      "Epoch: 95. Iteration: 64000. Mini-batch cost: 0.0626. Train accuracy:0.9800\n",
      "Epoch: 96. Iteration: 65000. Mini-batch cost: 0.0254. Train accuracy:1.0000\n",
      "Epoch: 98. Iteration: 66000. Mini-batch cost: 0.2552. Train accuracy:0.9200\n",
      "Epoch: 99. Iteration: 67000. Mini-batch cost: 0.0774. Train accuracy:0.9800\n",
      "Optimization Done\n",
      "Testing accuracy: 89.22\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "#class_weights = tf.constant([[1.5, 1.0]])\n",
    "\n",
    "# declare placeholders\n",
    "x = tf.placeholder(tf.float32, [None, 13])\n",
    "y = tf.placeholder(tf.float32, [None, 2])\n",
    "\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "\n",
    "cost, optimizer, accuracy, y_prediction = _create_network()\n",
    "\n",
    "epochs = 100\n",
    "num_train = len(X_train)\n",
    "batch_size = 50\n",
    "\n",
    "# train the network\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for _iter in range(epochs):\n",
    "        \n",
    "        begin = 0\n",
    "        while begin < num_train:\n",
    "            end = min(begin + batch_size, num_train)     \n",
    "            train_dict = {x:X_train[begin:end,], y:y_one_hot_train[begin:end]}\n",
    "            begin = end\n",
    "            \n",
    "            i_global, _, c, acc = sess.run([global_step, optimizer, cost, accuracy], feed_dict=train_dict)\n",
    "            \n",
    "            if i_global % 1000 == 0:\n",
    "                print(\"Epoch: {0}. Iteration: {1}. Mini-batch cost: {2:.4f}. Train accuracy:{3:.4f}\".format(_iter,\n",
    "                                                                                                    i_global,\n",
    "                                                                                                    c,\n",
    "                                                                                                    acc))\n",
    "    print(\"Optimization Done\")\n",
    "    \n",
    "    test_dict = {x:X_test, y:y_one_hot_test}\n",
    "    acc_test, y_pred = sess.run([accuracy, y_prediction], feed_dict=test_dict)\n",
    "    print(\"Testing accuracy: {0:.2f}\".format(acc_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.892180546726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score\n",
    "print(\"F1-score: {0}\".format(f1_score(y_test, y_pred, average='micro'))) # f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 356,    4],\n",
       "       [ 844, 6661]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_pred) # confusion matrix\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7505\n",
       "0     360\n",
       "Name: dead, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts() # true class counts of the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Training a neural net on a dataset with very few features is quite tricky. I adopted the following techniques before I obtained a decent result on the test set:\n",
    "\n",
    "1. I trained the net with the original imbalanced dataset and it was giving a very high accuracy. It is misleading since it is classifying everything to the majority class to incurr less error.\n",
    "2. I tried to train the model with penalised cross entropy loss. I was putting more stress on missclassification of the minority class as compared to the majority. But it turned out that the classifier was voting everything for the minority class. I was unable to find the optimum weights even with grid search on the weights.\n",
    "3. Finally, I tried SMOTE, where synthetic examples of the minority classes are generated. With this expanded dataset containing almost equal representation from both the classes, the model was indeed able to find a better classification boundary.\n",
    "\n",
    "As we can see, out of 360 <b>dead</b> observations, it is able to correctly classify <b>356</b> observations but it wrongly classifies more <b>alive</b> subjects as <b>dead</b> as compared to the other classifiers.\n",
    "\n",
    "Hence, in my case, the Neural Net was not able to outperform the Random Forest Classifier. Possible reason could be that a neural net is learning a complicated decision boundary that doesn't generalize too well on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
